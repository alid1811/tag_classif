"""
Module d'entra√Ænement des mod√®les de classification multilabel.
G√®re le pipeline complet: chargement, preprocessing, entra√Ænement et √©valuation.
"""

import os
import sys
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from typing import Optional, Dict, Tuple

# Import des modules du projet
from data import (
    load_json_files, 
    preprocess_data, 
    augment_rare_classes
)
from models import TfidfLogRegClassifier, TfidfMiniLMClassifier
from evaluation import evaluate_model


def train_tfidf_logreg(data_dir: str,
                       test_size: float = 0.2,
                       random_state: int = 42,
                       save_dir: str = "saved_models/tfidf_logreg",
                       report_dir: str = "reports/tfidf_logreg",
                       **model_params) -> Dict:
    """
    Entra√Æne un mod√®le TF-IDF + Logistic Regression.
    
    Args:
        data_dir (str): R√©pertoire contenant les fichiers JSON
        test_size (float): Proportion du jeu de test (entre 0 et 1)
        random_state (int): Seed pour la reproductibilit√©
        save_dir (str): R√©pertoire de sauvegarde du mod√®le
        report_dir (str): R√©pertoire pour les rapports d'√©valuation
        **model_params: Param√®tres suppl√©mentaires pour le mod√®le
        
    Returns:
        Dict: Dictionnaire contenant le mod√®le entra√Æn√© et les r√©sultats
    """
    print("\n" + "="*70)
    print("ENTRA√éNEMENT: TF-IDF + LOGISTIC REGRESSION")
    print("="*70)
    
    # 1. Chargement des donn√©es
    print("\nüìÇ Chargement des donn√©es...")
    df_raw = load_json_files(data_dir)
    
    # 2. Preprocessing
    df = preprocess_data(df_raw)
    
    # 3. Extraction des features et labels
    X = df["clean_text"].fillna("")
    y = df["raw"]
    
    print(f"üìä Nombre total d'exemples: {len(X)}")
    print(f"üìä Nombre de classes: {len(set([tag for tags in y for tag in tags]))}")
    
    # 4. Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    print(f"üîÄ Split effectu√©: {len(X_train)} train, {len(X_test)} test")
    
    # 5. Cr√©ation et entra√Ænement du mod√®le
    model = TfidfLogRegClassifier(**model_params)
    model.fit(X_train, y_train)
    
    # 6. Transformation des labels pour l'√©valuation
    Y_test = model.mlb.transform(y_test)
    
    # 7. √âvaluation
    results = evaluate_model(
        model, 
        X_test, 
        Y_test,
        class_names=list(model.mlb.classes_),
        output_dir=report_dir,
        model_name="TfidfLogReg"
    )
    
    # 8. Sauvegarde du mod√®le
    model.save(save_dir)
    
    print(f"\n‚úÖ Entra√Ænement termin√© avec succ√®s!")
    print(f"üìÅ Mod√®le sauvegard√©: {save_dir}/")
    print(f"üìÅ Rapports g√©n√©r√©s: {report_dir}/")
    
    return {
        'model': model,
        'results': results,
        'X_test': X_test,
        'y_test': y_test,
        'Y_test': Y_test
    }


def train_tfidf_minilm(data_dir: str,
                       test_size: float = 0.2,
                       random_state: int = 42,
                       augment_rare: bool = True,
                       rare_tags: Optional[list] = None,
                       augment_multiplier: int = 2,
                       use_custom_thresholds: bool = True,
                       save_dir: str = "saved_models/tfidf_minilm",
                       report_dir: str = "reports/tfidf_minilm",
                       **model_params) -> Dict:
    """
    Entra√Æne un mod√®le TF-IDF + MiniLM + Logistic Regression.
    
    Args:
        data_dir (str): R√©pertoire contenant les fichiers JSON
        test_size (float): Proportion du jeu de test
        random_state (int): Seed pour la reproductibilit√©
        augment_rare (bool): Si True, augmente les classes rares
        rare_tags (list): Liste des tags rares √† augmenter
        augment_multiplier (int): Facteur de multiplication pour l'augmentation
        use_custom_thresholds (bool): Si True, utilise des seuils personnalis√©s
        save_dir (str): R√©pertoire de sauvegarde du mod√®le
        report_dir (str): R√©pertoire pour les rapports
        **model_params: Param√®tres suppl√©mentaires pour le mod√®le
        
    Returns:
        Dict: Dictionnaire contenant le mod√®le entra√Æn√© et les r√©sultats
    """
    print("\n" + "="*70)
    print("ENTRA√éNEMENT: TF-IDF + MiniLM + LOGISTIC REGRESSION")
    print("="*70)
    
    # 1. Chargement des donn√©es
    print("\nüìÇ Chargement des donn√©es...")
    df_raw = load_json_files(data_dir)
    
    # 2. Preprocessing
    df = preprocess_data(df_raw)
    
    # 3. Extraction des features et labels
    X = df["clean_text"].fillna("")
    y = df["raw"]
    
    print(f"üìä Nombre total d'exemples: {len(X)}")
    
    # 4. Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    print(f"üîÄ Split effectu√©: {len(X_train)} train, {len(X_test)} test")
    
    # 5. Cr√©ation du mod√®le (n√©cessaire pour obtenir mlb)
    model = TfidfMiniLMClassifier(**model_params)
    
    # Transformation pr√©liminaire pour obtenir les classes
    from sklearn.preprocessing import MultiLabelBinarizer
    mlb_temp = MultiLabelBinarizer()
    Y_train = mlb_temp.fit_transform(y_train)
    Y_test = mlb_temp.transform(y_test)
    
    # 6. Augmentation des classes rares (optionnel)
    if augment_rare:
        if rare_tags is None:
            rare_tags = ["probabilities", "games", "geometry"]
        
        print(f"\nüìà Augmentation des classes rares: {rare_tags}")
        Y_train_df = pd.DataFrame(Y_train, columns=mlb_temp.classes_)
        X_train_aug, Y_train_aug = augment_rare_classes(
            X_train, 
            Y_train_df, 
            rare_tags, 
            multiplier=augment_multiplier
        )
        
        # Reconvertir y_train pour l'entra√Ænement
        y_train_aug = []
        for i in range(len(Y_train_aug)):
            tags = [mlb_temp.classes_[j] for j in range(len(mlb_temp.classes_)) 
                   if Y_train_aug[i][j] == 1]
            y_train_aug.append(tags)
        
        X_train = X_train_aug
        y_train = y_train_aug
    
    # 7. Entra√Ænement du mod√®le
    model.fit(X_train, y_train)
    
    # 8. Pr√©diction et √©valuation
    if use_custom_thresholds and rare_tags:
        print("\nüéØ Utilisation de seuils personnalis√©s pour les classes rares")
        thresholds = {cls: 0.3 if cls in rare_tags else 0.5 
                     for cls in model.mlb.classes_}
        Y_pred = model.predict_with_threshold(X_test, thresholds)
        
        # Cr√©er un wrapper pour l'√©valuation
        class ModelWrapper:
            def __init__(self, model, thresholds):
                self.model = model
                self.thresholds = thresholds
            
            def predict(self, X):
                return self.model.predict_with_threshold(X, self.thresholds)
        
        eval_model = ModelWrapper(model, thresholds)
    else:
        eval_model = model
    
    # Transformation des labels pour l'√©valuation
    Y_test_eval = model.mlb.transform(y_test)
    
    # 9. √âvaluation
    results = evaluate_model(
        eval_model, 
        X_test, 
        Y_test_eval,
        class_names=list(model.mlb.classes_),
        output_dir=report_dir,
        model_name="TfidfMiniLM"
    )
    
    # 10. Sauvegarde du mod√®le
    model.save(save_dir)
    
    print(f"\n‚úÖ Entra√Ænement termin√© avec succ√®s!")
    print(f"üìÅ Mod√®le sauvegard√©: {save_dir}/")
    print(f"üìÅ Rapports g√©n√©r√©s: {report_dir}/")
    
    return {
        'model': model,
        'results': results,
        'X_test': X_test,
        'y_test': y_test,
        'Y_test': Y_test_eval,
        'thresholds': thresholds if use_custom_thresholds and rare_tags else None
    }


def compare_models(data_dir: str,
                  test_size: float = 0.2,
                  random_state: int = 42) -> pd.DataFrame:
    """
    Compare les performances de plusieurs mod√®les.
    
    Args:
        data_dir (str): R√©pertoire contenant les donn√©es
        test_size (float): Proportion du jeu de test
        random_state (int): Seed pour la reproductibilit√©
        
    Returns:
        pd.DataFrame: DataFrame comparant les m√©triques des mod√®les
    """
    print("\n" + "="*70)
    print("COMPARAISON DES MOD√àLES")
    print("="*70)
    
    # Entra√Æner le mod√®le TF-IDF + LogReg
    print("\nüîπ Mod√®le 1/2: TF-IDF + LogReg")
    results_logreg = train_tfidf_logreg(
        data_dir,
        test_size=test_size,
        random_state=random_state,
        save_dir="saved_models/comparison/tfidf_logreg",
        report_dir="reports/comparison/tfidf_logreg"
    )
    
    # Entra√Æner le mod√®le TF-IDF + MiniLM
    print("\nüîπ Mod√®le 2/2: TF-IDF + MiniLM")
    results_minilm = train_tfidf_minilm(
        data_dir,
        test_size=test_size,
        random_state=random_state,
        save_dir="saved_models/comparison/tfidf_minilm",
        report_dir="reports/comparison/tfidf_minilm"
    )
    
    # Extraire les m√©triques macro avg
    logreg_metrics = results_logreg['results']['report_dict']['macro avg']
    minilm_metrics = results_minilm['results']['report_dict']['macro avg']
    
    logreg_add = results_logreg['results']['additional_metrics']
    minilm_add = results_minilm['results']['additional_metrics']
    
    # Cr√©er le DataFrame de comparaison
    comparison_df = pd.DataFrame({
        'Metric': ['Precision', 'Recall', 'F1-Score', 'Hamming Loss', 'Exact Match Ratio'],
        'TF-IDF + LogReg': [
            logreg_metrics['precision'],
            logreg_metrics['recall'],
            logreg_metrics['f1-score'],
            logreg_add['hamming_loss'],
            logreg_add['exact_match_ratio']
        ],
        'TF-IDF + MiniLM': [
            minilm_metrics['precision'],
            minilm_metrics['recall'],
            minilm_metrics['f1-score'],
            minilm_add['hamming_loss'],
            minilm_add['exact_match_ratio']
        ]
    })
    
    # Calculer la diff√©rence
    comparison_df['Diff√©rence'] = (
        comparison_df['TF-IDF + MiniLM'] - comparison_df['TF-IDF + LogReg']
    )
    
    # Sauvegarder la comparaison
    os.makedirs("reports/comparison", exist_ok=True)
    comparison_df.to_csv("reports/comparison/models_comparison.csv", index=False)
    
    print("\n" + "="*70)
    print("R√âSULTATS DE LA COMPARAISON")
    print("="*70)
    print(comparison_df.to_string(index=False))
    print("="*70)
    
    print(f"\nüíæ Comparaison sauvegard√©e: reports/comparison/models_comparison.csv")
    
    return comparison_df


if __name__ == "__main__":
    print("Module train_model.py - Fonctions d'entra√Ænement disponibles")
    print("- train_tfidf_logreg(): Entra√Æne TF-IDF + LogReg")
    print("- train_tfidf_minilm(): Entra√Æne TF-IDF + MiniLM + LogReg")
    print("- compare_models(): Compare les deux mod√®les")